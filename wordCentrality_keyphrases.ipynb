{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,LSTM, Embedding, Dense, TimeDistributed, Dropout, Conv1D,GRU,BatchNormalization, Concatenate\n",
    "from tensorflow.keras.layers import Bidirectional, concatenate, SpatialDropout1D, GlobalMaxPooling1D,dot,Activation\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from seqeval.metrics import classification_report, accuracy_score\n",
    "import transformers\n",
    "import torch\n",
    "from keras import backend as K \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertConfig\n",
    "tokenizer_class = transformers.BertTokenizer\n",
    "model_class = transformers.BertModel\n",
    "config = BertConfig.from_pretrained('gsarti/biobert-nli', output_hidden_states=True)\n",
    "tokenizer = tokenizer_class.from_pretrained('gsarti/biobert-nli')\n",
    "bert_model = model_class.from_pretrained('gsarti/biobert-nli',config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and process training and test data\n",
    "import pickle\n",
    "with open('tagged_abstracts.pickle', 'rb') as handle:\n",
    "    abstracts = pickle.load(handle) \n",
    "    \n",
    "words, tags = [], []\n",
    "for sent in abstracts:\n",
    "    for wrd in sent:\n",
    "        words.append(wrd[0])\n",
    "        tags.append(wrd[1])\n",
    "        \n",
    "words = list(set(words))        \n",
    "words.append('ENDPAD')\n",
    "tags = list(set(tags))      \n",
    "\n",
    "max_len = 200\n",
    "word2idx = {w: i+1 for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "idx2words = {}\n",
    "for w,i in word2idx.items():\n",
    "    idx2words[i] = w\n",
    "\n",
    "docs = [\" \".join([w[0] for w in s]) for s in abstracts]\n",
    "yy =  [[w[1] for w in s] for s in abstracts]\n",
    "\n",
    "X = [[word2idx[w[0]] for w in s] for s in abstracts]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value= 0)\n",
    "\n",
    "n_tags = 3\n",
    "y = [[tag2idx[w[1]] for w in s] for s in abstracts]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"],dtype=object)\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Bert Embeddings\n",
    "\n",
    "def get_word_embeddings(text):\n",
    "    \n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    if len(tokenized_text) > 500:\n",
    "        tokenized_text = tokenized_text[:500]\n",
    "\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "    \n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoded_layers = bert_model(tokens_tensor, segments_tensors)\n",
    "        \n",
    "    token_embeddings = torch.stack(encoded_layers[2], dim=0)   \n",
    "    \n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "    \n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "    \n",
    "    token_vecs_sum = []\n",
    "\n",
    "\n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "\n",
    "        # Sum the vectors from the last four layers.\n",
    "        sum_vec = torch.sum(token[-4:], dim=0)\n",
    "\n",
    "        # Use `sum_vec` to represent `token`.\n",
    "        token_vecs_sum.append(sum_vec)\n",
    "        \n",
    "    new_tokens = []    \n",
    "    new_vecs = []\n",
    "    for i, token_str in enumerate(tokenized_text):\n",
    "        if token_str.startswith(\"##\"):\n",
    "            new_tokens[-1] = new_tokens[-1] + token_str[2:]\n",
    "            new_vecs[-1] = torch.mean(torch.stack((new_vecs[-1],token_vecs_sum[i])), dim=0)\n",
    "            \n",
    "        else:\n",
    "            new_tokens.append(token_str)\n",
    "            new_vecs.append(token_vecs_sum[i])\n",
    "    for tk, vec in zip(new_tokens,new_vecs):\n",
    "        final_embed_vecs[tk] = vec\n",
    "        \n",
    "\n",
    "final_embed_vecs = {}\n",
    "for item in docs:\n",
    "    get_word_embeddings(item)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word input embedding matrix\n",
    "vocab_size = len(words) + 1\n",
    "embedding_matrix = np.random.rand(vocab_size,768)\n",
    "for word,i in word2idx.items():\n",
    "\n",
    "    if word in final_embed_vecs:\n",
    "        embedding_matrix[i] = final_embed_vecs[word]\n",
    "    else:\n",
    "        embedding_matrix[i] = np.random.rand(1,768) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Document embedding for train and test sets\n",
    "#We average the Bert word embeddings for document\n",
    "\n",
    "import re\n",
    "train_matrix = []\n",
    "for item in X_train:\n",
    "    col = []\n",
    "    agg = []\n",
    "    count = 0\n",
    "    for it in item:\n",
    "        try:\n",
    "            wrd = idx2words[it]\n",
    "            wrd = re.sub('[^a-zA-Z-]+', '', wrd)\n",
    "            col.append(final_embed_vecs[wrd])\n",
    "            count+=1\n",
    "        except:\n",
    "            pass\n",
    "    avrg = torch.mean(torch.stack(col), dim=0)   \n",
    "    for it in item:\n",
    "        agg.append(avrg.detach().numpy())\n",
    "    \n",
    "    train_matrix.append(agg)  \n",
    "    \n",
    "    \n",
    "test_matrix = []\n",
    "for item in X_test:\n",
    "    col = []\n",
    "    agg = []\n",
    "    count = 0\n",
    "    for it in item:\n",
    "        try:\n",
    "            wrd = idx2words[it]\n",
    "            wrd = re.sub('[^a-zA-Z-]+', '', wrd)\n",
    "            col.append(final_embed_vecs[wrd])\n",
    "            count+=1\n",
    "        except:\n",
    "            pass\n",
    "    avrg = torch.mean(torch.stack(col), dim=0)   \n",
    "    for it in item:\n",
    "        agg.append(avrg.detach().numpy())\n",
    "    \n",
    "    test_matrix.append(agg)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRF Class \n",
    "\n",
    "from tensorflow_addons.text import crf_log_likelihood, crf_decode\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow as tf\n",
    "\n",
    "class CRF(L.Layer):\n",
    "    def __init__(self,\n",
    "                 output_dim,\n",
    "                 sparse_target=True,\n",
    "                 **kwargs):\n",
    "        \"\"\"    \n",
    "        Args:\n",
    "            output_dim (int): the number of labels to tag each temporal input.\n",
    "            sparse_target (bool): whether the the ground-truth label represented in one-hot.\n",
    "        Input shape:\n",
    "            (batch_size, sentence length, output_dim)\n",
    "        Output shape:\n",
    "            (batch_size, sentence length, output_dim)\n",
    "        \"\"\"\n",
    "        super(CRF, self).__init__(**kwargs)\n",
    "        self.output_dim = int(output_dim) \n",
    "        self.sparse_target = sparse_target\n",
    "        self.input_spec = L.InputSpec(min_ndim=3)\n",
    "        self.supports_masking = False\n",
    "        self.sequence_lengths = None\n",
    "        self.transitions = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        f_shape = tf.TensorShape(input_shape)\n",
    "        input_spec = L.InputSpec(min_ndim=3, axes={-1: f_shape[-1]})\n",
    "\n",
    "        if f_shape[-1] is None:\n",
    "            raise ValueError('The last dimension of the inputs to `CRF` '\n",
    "                             'should be defined. Found `None`.')\n",
    "        if f_shape[-1] != self.output_dim:\n",
    "            raise ValueError('The last dimension of the input shape must be equal to output'\n",
    "                             ' shape. Use a linear layer if needed.')\n",
    "        self.input_spec = input_spec\n",
    "        self.transitions = self.add_weight(name='transitions',\n",
    "                                           shape=[self.output_dim, self.output_dim],\n",
    "                                           initializer='glorot_uniform',\n",
    "                                           trainable=True)\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        # Just pass the received mask from previous layer, to the next layer or\n",
    "        # manipulate it if this layer changes the shape of the input\n",
    "        return mask\n",
    "\n",
    "    def call(self, inputs, sequence_lengths=None, training=None, **kwargs):\n",
    "        sequences = tf.convert_to_tensor(inputs, dtype=self.dtype)\n",
    "        if sequence_lengths is not None:\n",
    "            assert len(sequence_lengths.shape) == 2\n",
    "            assert tf.convert_to_tensor(sequence_lengths).dtype == 'int32'\n",
    "            seq_len_shape = tf.convert_to_tensor(sequence_lengths).get_shape().as_list()\n",
    "            assert seq_len_shape[1] == 1\n",
    "            self.sequence_lengths = K.flatten(sequence_lengths)\n",
    "        else:\n",
    "            self.sequence_lengths = tf.ones(tf.shape(inputs)[0], dtype=tf.int32) * (\n",
    "                tf.shape(inputs)[1]\n",
    "            )\n",
    "\n",
    "        viterbi_sequence, _ = crf_decode(sequences,\n",
    "                                         self.transitions,\n",
    "                                         self.sequence_lengths)\n",
    "        output = K.one_hot(viterbi_sequence, self.output_dim)\n",
    "        return K.in_train_phase(sequences, output)\n",
    "\n",
    "    @property\n",
    "    def loss(self):\n",
    "        def crf_loss(y_true, y_pred):\n",
    "            y_pred = tf.convert_to_tensor(y_pred, dtype=self.dtype)\n",
    "            log_likelihood, self.transitions = crf_log_likelihood(\n",
    "                y_pred,\n",
    "                tf.cast(K.argmax(y_true), dtype=tf.int32) if self.sparse_target else y_true,\n",
    "                self.sequence_lengths,\n",
    "                transition_params=self.transitions,\n",
    "            )\n",
    "            return tf.reduce_mean(-log_likelihood)\n",
    "        return crf_loss\n",
    "\n",
    "    @property\n",
    "    def accuracy(self):\n",
    "        def viterbi_accuracy(y_true, y_pred):\n",
    "            # -1e10 to avoid zero at sum(mask)\n",
    "            mask = K.cast(\n",
    "                K.all(K.greater(y_pred, -1e10), axis=2), K.floatx())\n",
    "            shape = tf.shape(y_pred)\n",
    "            sequence_lengths = tf.ones(shape[0], dtype=tf.int32) * (shape[1])\n",
    "            y_pred, _ = crf_decode(y_pred, self.transitions, sequence_lengths)\n",
    "            if self.sparse_target:\n",
    "                y_true = K.argmax(y_true, 2)\n",
    "            y_pred = K.cast(y_pred, 'int32')\n",
    "            y_true = K.cast(y_true, 'int32')\n",
    "            corrects = K.cast(K.equal(y_true, y_pred), K.floatx())\n",
    "            return K.sum(corrects * mask) / K.sum(mask)\n",
    "        return viterbi_accuracy\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        tf.TensorShape(input_shape).assert_has_rank(3)\n",
    "        return input_shape[:2] + (self.output_dim,)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'output_dim': self.output_dim,\n",
    "            'sparse_target': self.sparse_target,\n",
    "            'supports_masking': self.supports_masking,\n",
    "            'transitions': K.eval(self.transitions)\n",
    "        }\n",
    "        base_config = super(CRF, self).get_config()\n",
    "        return dict(base_config, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model architecture \n",
    "\n",
    "num_labels = 3\n",
    "embedding_size = 768\n",
    "hidden_size = 4\n",
    "\n",
    "#Input the word embeddings  \n",
    "input= Input(shape=(max_len,))\n",
    "model = Embedding(vocab_size, embedding_size, trainable=False,weights=[embedding_matrix],input_length=max_len)(input)\n",
    "model = Dropout(0.55)(model)\n",
    "model = Bidirectional(LSTM(64, return_sequences=True))(model)\n",
    "\n",
    "#Input the document embedding matrix\n",
    "auxiliary_input = Input(shape=(200,768))\n",
    "x = Bidirectional(LSTM(hidden_size, return_sequences=True))(auxiliary_input)\n",
    "x = Dropout(0.65)(x)\n",
    "\n",
    "#Calculate the alignment score and apply softmax\n",
    "attention = dot([model, x], axes=[1, 1])\n",
    "attention = Activation('softmax')(attention)\n",
    "context = dot([attention, model], axes=[1,2])\n",
    "context = BatchNormalization(momentum=0.6)(context)\n",
    "context = K.permute_dimensions(context, (0,2,1))\n",
    "\n",
    "#Concatenate the contex vector and the word inputs \n",
    "concated = concatenate([model, context])\n",
    "main_output = Dense(3)(concated)\n",
    "\n",
    "#Pass output through CRF layer \n",
    "crf = CRF(n_tags) \n",
    "out = crf(main_output)\n",
    "\n",
    "model = Model(inputs=[input, auxiliary_input], outputs=out)\n",
    "adam = optimizers.Adam(lr = 0.001)\n",
    "model.compile(adam,loss=crf.loss, metrics=[crf.accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=50, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('keywords_SL.hdf5', save_weights_only=True,save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=20, verbose=1, mode='min', min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 40.2850 - viterbi_accuracy: 0.9152 - val_loss: 133.8246 - val_viterbi_accuracy: 0.8995\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 14s 1s/step - loss: 39.9210 - viterbi_accuracy: 0.9160 - val_loss: 133.8925 - val_viterbi_accuracy: 0.8969\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 39.7310 - viterbi_accuracy: 0.9167 - val_loss: 133.4041 - val_viterbi_accuracy: 0.8973\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 14s 970ms/step - loss: 39.2893 - viterbi_accuracy: 0.9172 - val_loss: 133.0379 - val_viterbi_accuracy: 0.8966\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 14s 990ms/step - loss: 39.0850 - viterbi_accuracy: 0.9184 - val_loss: 132.0300 - val_viterbi_accuracy: 0.8993\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 15s 1s/step - loss: 39.0533 - viterbi_accuracy: 0.9174 - val_loss: 132.4186 - val_viterbi_accuracy: 0.8969\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 38.5745 - viterbi_accuracy: 0.9189 - val_loss: 131.8386 - val_viterbi_accuracy: 0.8981\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 17s 1s/step - loss: 38.2871 - viterbi_accuracy: 0.9186 - val_loss: 131.7001 - val_viterbi_accuracy: 0.8970\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 17s 1s/step - loss: 38.1531 - viterbi_accuracy: 0.9191 - val_loss: 131.2270 - val_viterbi_accuracy: 0.8973\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 37.8120 - viterbi_accuracy: 0.9197 - val_loss: 130.8998 - val_viterbi_accuracy: 0.8972\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 17s 1s/step - loss: 37.5615 - viterbi_accuracy: 0.9204 - val_loss: 130.7861 - val_viterbi_accuracy: 0.8808\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 17s 1s/step - loss: 37.4050 - viterbi_accuracy: 0.9202 - val_loss: 129.8031 - val_viterbi_accuracy: 0.8847\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 16s 1s/step - loss: 37.2690 - viterbi_accuracy: 0.9201 - val_loss: 129.3168 - val_viterbi_accuracy: 0.8816\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 17s 1s/step - loss: 36.8963 - viterbi_accuracy: 0.9206 - val_loss: 129.9444 - val_viterbi_accuracy: 0.8769\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 17s 1s/step - loss: 36.8578 - viterbi_accuracy: 0.9211 - val_loss: 128.9934 - val_viterbi_accuracy: 0.8814\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 19s 1s/step - loss: 36.5131 - viterbi_accuracy: 0.9210 - val_loss: 129.3505 - val_viterbi_accuracy: 0.8771\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 23s 2s/step - loss: 36.2300 - viterbi_accuracy: 0.9215 - val_loss: 128.5880 - val_viterbi_accuracy: 0.8786\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 19s 1s/step - loss: 35.9317 - viterbi_accuracy: 0.9220 - val_loss: 128.3926 - val_viterbi_accuracy: 0.8793\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 19s 1s/step - loss: 35.9027 - viterbi_accuracy: 0.9225 - val_loss: 128.5385 - val_viterbi_accuracy: 0.8769\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 19s 1s/step - loss: 35.6640 - viterbi_accuracy: 0.9224 - val_loss: 127.9973 - val_viterbi_accuracy: 0.8785\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 19s 1s/step - loss: 35.4337 - viterbi_accuracy: 0.9230 - val_loss: 127.4566 - val_viterbi_accuracy: 0.8797\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 19s 1s/step - loss: 35.1394 - viterbi_accuracy: 0.9233 - val_loss: 127.5497 - val_viterbi_accuracy: 0.8773\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 18s 1s/step - loss: 35.1755 - viterbi_accuracy: 0.9234 - val_loss: 127.0613 - val_viterbi_accuracy: 0.8782\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 19s 1s/step - loss: 34.8409 - viterbi_accuracy: 0.9239 - val_loss: 126.8307 - val_viterbi_accuracy: 0.8780\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 17s 1s/step - loss: 34.6429 - viterbi_accuracy: 0.9241 - val_loss: 126.7768 - val_viterbi_accuracy: 0.8604\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 18s 1s/step - loss: 34.4645 - viterbi_accuracy: 0.9250 - val_loss: 127.0296 - val_viterbi_accuracy: 0.8585\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 20s 1s/step - loss: 34.2801 - viterbi_accuracy: 0.9248 - val_loss: 126.4370 - val_viterbi_accuracy: 0.8574\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 19s 1s/step - loss: 34.2830 - viterbi_accuracy: 0.9250 - val_loss: 125.6690 - val_viterbi_accuracy: 0.8618\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 18s 1s/step - loss: 34.1213 - viterbi_accuracy: 0.9249 - val_loss: 126.4447 - val_viterbi_accuracy: 0.8580\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 18s 1s/step - loss: 33.8770 - viterbi_accuracy: 0.9250 - val_loss: 125.5579 - val_viterbi_accuracy: 0.8614\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "history = model.fit([np.array(X_train),np.array(train_matrix)], np.asarray(y_train), batch_size=128, epochs=num_epochs, validation_split=0.15, verbose=1, callbacks = [earlyStopping, mcp_save,reduce_lr_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 117ms/step\n",
      "           precision    recall  f1-score   support\n",
      "\n",
      "      KEY       0.74      0.68      0.71     12568\n",
      "\n",
      "micro avg       0.74      0.68      0.71     12568\n",
      "macro avg       0.74      0.68      0.71     12568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict([np.array(X_test),np.array(test_matrix)], verbose=1)\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "\n",
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i].replace(\"PAD\", \"O\"))\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "    \n",
    "pred_labels = pred2label(test_pred)\n",
    "test_labels = pred2label(y_test)\n",
    "\n",
    "print(classification_report(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
